<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0"
    />

    <title>AI - Table of Contents | LLM Models, Claude, MCP & Tools</title>
  </head>
  <body class="layout bg" toc>
    <div class="body">
      <div class="inside">
        <div class="cards toc">
          <h1>Table of Contents</h1>
          <ul data-do-sort>
            <li><a href="claude.html">Claude</a></li>
            <li><a href="gemini.html">Gemini CLI</a></li>
            <li><a href="mcp.rendered.html">MCP</a></li>
            <li><a href="opencode.html">Opencode</a></li>
            <li><a href="aitoolkit.html">AI Toolkit</a></li>
            <li><a href="warp.html">Warp AI</a></li>
            <li><a href="antigravity.html">Antigravity</a></li>
          </ul>
        </div>
        <h2>Alternative to ChatGPT</h2>
        <script type="editor" data-lang="python">

          https://chat.openai.com/chat
            chatgpt itself

          https://gemini.google.com/app
          https://claude.ai/new
          https://chat.deepseek.com/
          https://chat.ai-pro.org/chat
          https://poe.com/
          https://agent.minimax.io/
        </script>
        <h2>Building Agents</h2>
        <script type="editor" data-lang="python">

          Agent Development Kit  https://youtu.be/ZKxYZdbYuWs
        </script>
        <h2>MD files</h2>
        <script type="editor" data-lang="python">

          https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/tree/main/Google/Antigravity
        </script>

        <h2>Various</h2>

        <script type="editor" data-lang="python">

          # tokenizer:
            https://huggingface.co/spaces/Xenova/the-tokenizer-playground
        </script>
        <h2>RAG -</h2>
        <script type="editor" data-lang="python">

          https://www.youtube.com/@daveebbelaar
        </script>
        <h2>Open models - self-hosted</h2>
        <script type="editor" data-lang="python">

          ollama + openwebui
            from: https://youtu.be/illvibK_ZmY?t=158

          huggingface

          ChatGPT forks UI:
            openwebui
              from: https://youtu.be/illvibK_ZmY?t=215
            LIbreChat:
              from: https://youtu.be/illvibK_ZmY?t=688

          n8n
            from: https://youtu.be/illvibK_ZmY?t=294

          localAi
            from: https://youtu.be/illvibK_ZmY?t=363

          Whisper & WhisperX
            OpenAI - transcripton model (audo to text)
            from: https://youtu.be/illvibK_ZmY?t=534

          Stable Diffusion WebUI
            (text to image)
            from: https://youtu.be/illvibK_ZmY?t=601

            ComfyUI:
              from: https://youtu.be/illvibK_ZmY?t=744
              you have pipelines (like n8n) to control better stable diffusion

          with RAG
            AnythingLLM: that is with RAG
              from: https://youtu.be/illvibK_ZmY?t=420
            PrivateGPT:
              from: https://youtu.be/illvibK_ZmY?t=644


          IBM Granite 4.0
            https://youtu.be/31r6yxbmrFo
              talks about transformers.js https://youtu.be/NLQ_gVcjHHA
              and project using it locally: https://github.com/andrisgauracs/AI-Code-Assistant

          sound cleaning - refining - separating sounds:
            g(sam audio)

          Images:          
            OCR:
              https://youtu.be/-D7o3E0eBf4?t=116

            Object removal:
              OmnimatteZero: https://youtu.be/-D7o3E0eBf4?t=2151

          Video:
            Transfer movements from video onto another character
              3DiMo, 3D-Aware Implicit Motion control. 
                  https://youtu.be/-D7o3E0eBf4?t=2284

              Change video to match new audio:
                FastVMT: https://youtu.be/-D7o3E0eBf4?t=2573
              
          EXO
            run LLM on multiple machines:
            pipeline sharding
            tensor parallelism
              https://youtu.be/A0onppIyHEg
        </script>
        <h2>Leaderboard</h2>
        <script type="editor" data-lang="python">

          # leaderboards
            p(what is best ranking (most trustworthy) to determine best llm model to use with IDE's for coding (like with claude)? any leaderboard? and how to use those)
            # for coding:
              https://livebench.ai/?utm_source=chatgpt.com#/
              https://stopsopa.github.io/start.html
              https://codingscape.com/blog/best-llms-for-coding-developer-favorites?utm_source=chatgpt.com
              https://blog.promptlayer.com/best-llms-for-coding/   comercial and open models
              https://aider.chat/docs/leaderboards/?utm_source=chatgpt.com
                # shows cost

            # coding - open models
              https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/

            # popular
              https://lmarena.ai/leaderboard
              https://artificialanalysis.ai/leaderboards/models
              https://evalplus.github.io/leaderboard.html

          // image generation
            https://www.freepik.com/

          // image to prompt
            https://flux-ai.io/flux-ai-image-to-prompt/

          // AI image editor
            https://bfl.ai/models/flux-kontext
              from: https://youtu.be/gh_g9uBd0m8?t=67

          Final ranking of models I use (as of 2025-09-13)
          powerful:
          gpt-5-high
          claude-4.1-opus max only
          gemini-2.5-pro
          deepseek-r1-0528
          o3-pro max only
          grok-4

          fast:
          gpt-5-high-fast

          text:
          o3-pro max only
        </script>
        <h2>Git Co-Authoer credits to AI</h2>
        <script type="editor" data-lang="sh">

          It is possible that this is called one of:
            - Co-authored-by trailer
            - Git commit trailers
            - commit footers
            - Git Trailer
            -
            -
            -
            -
            -
            -
            -
            -

          ---

          adding to git commit:
          "
          ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)  Co-Authored-By: Claude <noreply@anthropic.com>
          "
          NOTE: THAT CAN BE FOUND GLOBALLY WITH https://github.com/search?q=org%3Aanthropics%20Co-authored-by&type=code
          Other variations:
            - Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
            - Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"

          will refer to account: https://github.com/claude
            For example in this commit: https://github.com/stopsopa/dividing/commit/1a38a68206b1a4b868ab3e7aef036027db97f08b
          ---
          Another example of automatet contribution to the commit is here
          https://github.com/stopsopa/tsdi-lite/commit/50d08eec268f55a9e2b53dd4b5e4a86475175b0a
            it refers to semantic-release-bot https://github.com/semantic-release-bot

          ---
          My attempt to follow claude pattern to create proper footer for antigravity:
          First I've tried to find if anyone have done it already: https://github.com/search?q=Co-authored-by+antigravity&type=code
            Seems it found:
              - Co-Authored-By: Gemini 2.5 Flash (Antigravity) <noreply@google.com>
              - ðŸ¤– Generated with [Antigravity](http://antigravity.google/) Co-Authored-By: Antigravity <noreply@antigravity.google>
              - Co-authored-by: Antigravity <antigravity@google.deepmind.com>
        </script>

        <h2>Certificates</h2>
        <script type="editor" data-lang="sh">
          Nvidia certification: https://youtu.be/UZuWeLjyT3c?t=406
        </script>
        <h2>Security</h2>
        <script type="editor" data-lang="sh">

          Aardvark:
            https://openai.com/index/introducing-aardvark/
            from: https://youtu.be/8W_IUoSMvu0?t=399
        </script>
        <h2>Javascript libraries</h2>

        <script type="editor" data-lang="sh">

          // Google Gen AI SDK for TypeScript and JavaScript
            // https://github.com/googleapis/js-genai
        </script>
        <h2>Text -> Images</h2>
        <script type="editor" data-lang="sh">

          // https://sora.chatgpt.com/explore
        </script>
        <h2>audio to text</h2>
        <script type="editor" data-lang="sh">

          // https://youtu.be/Lp50z_XudYI
          // app: "Voice Memos"
          // format accepted *.m4a (aac internally)
          // use QuickTime to convert audio and video to m4a
        </script>
        <h2>Interesting links</h2>
        <a href="https://arena.lmsys.org/">https://arena.lmsys.org/</a>
        <br />
        <a href="https://www.realornotquiz.com/">https://www.realornotquiz.com/</a>
        <h2>prompting</h2>
        <script type="editor" data-lang="sh">


          // --- multi phase plans --- vvv
            When doing PLAN.md work on it with this prompt
              WARNING: WE ARE WORKING ONLY ON PLAN.md RIGHT NOW. DON'T START IMPLEMENTATION.
            Then when PLAN.md will be created add immediately under each title for each phase:
              ## Phase 5: Progress Visualization (STEP 5)
              WARNING: FOCUS ONLY ON THE SCOPE OF THIS PHASE. - don't implement anything that is not in the scope of this phase. it is allowed now to edit logic of calling @driveCompression.ts at this phase
            ... something like that. That seems to help to keep LLM on the subject. To avoid it from this ... "semantic drift", "cumulative drift" or "prompt or topic drift"
          // --- multi phase plans --- ^^^

          Persona:
            .. refers to what  expertise you want generative AI tool to draw from
            system prompt
            user prompt
          Context:
            Important rule: tell it that is ok to not know. "If you don't know then tell me you don't know, don't make things up"
            This is one of the best fix for halucination
          Format: https://youtu.be/pwWBcsxEoLk?t=660
            Few shot example/prompting: https://youtu.be/pwWBcsxEoLk?t=755
          Chain of thought: https://youtu.be/pwWBcsxEoLk?t=828
          Adverserial validation: https://youtu.be/pwWBcsxEoLk?t=986

          # some prompts:
            What is your knowledge cutoff date?
            What is the latest date your training data includes?
            Until what date does your built-in knowledge extend?
        </script>
        <h2>VScode</h2>

        <script type="editor" data-lang="sh">
          Agent modes: https://www.youtube.com/watch?v=dutyOc_cAEU
        </script>

        <h2>Local LLMs</h2>

        <script type="editor" data-lang="sh">

          https://youtu.be/MgjJvOUyD_0?t=125
          see also:
            https://www.reddit.com/r/LocalLLaMA/comments/1jhdml5/anyone_running_local_llms_on_an_m4_macbook_pro_or/

          setup on MAC m4 mini:
            https://youtu.be/j7yumDPWAEA?t=322
            best models to choose from: https://apxml.com/posts/best-local-llm-apple-silicon-mac

          starcoder model ??
          https://ollama.com/library/codellama
            from: https://youtu.be/_KGk9CMAYj4?t=325

          MiniMax:
            https://www.minimax.io/news/minimax-m2
            from: https://youtu.be/xt6_zIKeX6A?t=52
        </script>
      </div>
    </div>
    <script type="module" src="/js/github.js"></script>
  </body>
</html>
